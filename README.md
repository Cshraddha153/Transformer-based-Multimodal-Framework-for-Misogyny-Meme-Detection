# Transformer-based-Multimodal-Framework-for-Misogyny-Meme-Detection

# Desciption
This research focuses on detecting misogynistic content in Tamil and Malayalam memes using a multimodal approach. We extract image features using ViT (Vision Transformer) and text features using XLM-RoBERTa, then fuse these features for classification. Both machine learning (ML) and deep learning (DL) models were trained for misogyny detection. The research paper is currently under review at NAACL 2025.

# Methodology
=> Image Feature Extraction: ViT (Vision Transformer)
=> Text Feature Extraction: XLM-RoBERTa
=> Feature Fusion: Combined visual and textual features for classification
=> Models Used:
=> Machine Learning Models: KNN, SVM, Random Forest (RF), NaÃ¯ve Bayes (NB)
=> Deep Learning Models: LSTM, GRU, Custom Multimodal Model (MMC)

# Research Paper
Under Review

# Transformer-based-Multimodal-Framework-for-Misogyny-Meme-Detection

# Desciption
This research focuses on detecting misogynistic content in Tamil and Malayalam memes using a multimodal approach. We extract image features using ViT (Vision Transformer) and text features using XLM-RoBERTa, then fuse these features for classification. Both machine learning (ML) and deep learning (DL) models were trained for misogyny detection. The research paper is currently under review at NAACL 2025.

# Methodology
1. Image Feature Extraction: ViT (Vision Transformer)
2. Text Feature Extraction: XLM-RoBERTa
3. Feature Fusion: Combined visual and textual features for classification
   
# Models Used:
1. Machine Learning Models: KNN, SVM, Random Forest (RF), Na√Øve Bayes (NB)
2. Deep Learning Models: LSTM, GRU, Custom Multimodal Model (MMC)

# Research Paper
Under Review
